Usage: qdda [-D] [-B blksize] [-b <bandw>] [-c] [-d] [-f <dbpath>] [h|H] [-i importdb] 
            [-k] [-n] [-q] [-r] [-t [gb]] [-v] [-x] [device list]
  -D (debug)        : Show lots of annoying debug info
  -B <blksize_kb>   : Set blocksize to blksize_kb kilobytes
  -P (purge)        : Reclaim unused space in database (sqlite vacuum)
  -T <tempdir>      : Use tempdir instead of /var/tmp for SQLite temp files
  -a (append)       : Append data to existing database
  -b <bandw>        : Throttle bandwidth in MB/s (default 200, set to 0 to disable throttling)
  -c <method|l>     : Compression method for reporting (use -c l to list methods)
  -d (dump)         : Dump block offsets and hashes (to search for block offset with hash)
  -f <database>     : Specify alternative database location (default /var/tmp/qdda.db)
  -i <import-db>    : Import data from another database (merge with existing data)
  -n (noupdate)     : Dryrun - just read data (no update to database)
  -q (quiet)        : Don't show progress indicator or intermediate results
  -r (no-Report)    : Don't show report, don't merge staging data and keep staging database
  -t [size_gb|0]    : Run raw performance test (size_gb 0) or merge test (data size in GB)
  -V (version)      : print version and copyright info
  -x (eXtended)     : Extended report (file info and dedupe/compression histograms)
  -h or ? (help)    : This help
  -H Long help      : More detailed information, tips & tricks

qdda is safe to run even on files/devices that are in use. It opens streams read-only and cannot modify any files.
It writes to a database file that needs to be either newly created or a pre-existing SQLite3 database.
It can remove the database file but ONLY if it is an SQLite3 file.

See the long help for additional safety options.

                      *** Overview ***
total               = Total data blocks scanned
used                = Used (non-zero) space
deduped             = Required space after deduplication
allocated           = Required space after applying compression (array specific)
                      *** Details ***
Compression method  = Description of array/method
blocksize           = Dedupe blocksize
free (zero)         = Zeroed blocks (not allocated)
compress pre dedup  = Sum of bytes of compressed blocks (before dedupe)
merged by dedupe    = Space saved by deduplication
compress post dedup = Sum of bytes of compressed blocks (after dedupe)
unique data         = Blocks that can't be deduped
duped 2:1           = Blocks that are deduped 2:1
duped >2x           = Blocks that are deduped more than 2:1
duped total         = Blocks that are deduped 2:1 or more
                      *** Summary ***
percentage used     = Used capacity / Total capacity
percentage free     = Free capacity (zeroed)
deduplication ratio = used capacity / deduped capacity
compression ratio   = deduped and compressed / deduped
thin ratio          = Free capacity / Total capacity
combined            = dedup * compressed * thin ratio
raw capacity        = Total scanned (allocated)
net capacity        = Total required after optimizations

Hash calculations are highly accurate up to roughly 10TB data using 16K blocksize,
after which hash collisions may cause increasingly inaccurate results.

More info: http://outrun.nl/wiki/qdda
