
How qdda works:

Each stream (device, file or pipe) is scanned where each block is hashed and compressed.

The results (hash,compressed_bytes) go into a staging table. At the end of processing, the
staging data is merged into the main kv table (which actually holds 3 columns: hash - count - compressed_bytes).

The report is then generated by querying the kv table.

Hashing:

The hash value is a 7-byte truncated MD5 sum (tradeoff between database limits, efficiency
and low chance of hash collisions when scanning very large data sets).
Although storage arrays typically use the SHA algorithm with higher number of bits, MD5 has
better performance, and a very low amount of collisions will not impact the results or cause data corruption.
Hash collisions occur on average once in a 5 TB dataset at 16K blocksize.

See also https://en.wikipedia.org/wiki/Birthday_problem#Probability_table

Compression:

Some All-Flash arrays use "bucket" compression to achieve high throughput, low overhead and good compression. 
qdda simulates compression uzing LZ4 compression. LZ4 has very high throughput and the compression ratios
are very close to what All-Flash Arrays can achieve.

Bucket Compression:

QDDA knows 3 bucket compression scenarios and selects bucket compression based on the blocksize used:

8K blocksize   - available buckets are 2K, 4K and 8K (simulates XtremIO v1)
16K blocksize  - available buckets are 1K through 16K with 1K increments except 15K (XtremIO v2)
128K blocksize - available buckets are 8K through 128K with 8K increments (VMAX All-Flash - experimental, unverified!)

List available methods using option '-c l'

Throttling:

qdda processes 64 blocks per cycle and measures the service time. If the service time is too low it means the throughput is
higher than the bandwidth limit. The CPU is put to sleep for a number of microseconds to match the overall bandwidth limit.
This prevents accidentally starving IO on a production host. Disable with '-b 0' option or set different bandwidth

Blocksize:

The default blocksize is 16KiB to match modern All flash Arrays. The block size is stored in metadata and only datasets
with matching blocksizes can be merged. qdda reports X1 compression if a blocksize of 8K is detected, X2 if
the default 16K is detected, or VMAX AFA compression for 128K blocksize. I will not report compression ratios with other
blocksizes unless you load the bucketsizes and descriptions in the bucket tables after creating the database.

Space requirements (sizing)

Tables with index require 20 bytes per block data + 20 bytes index, which means for a 1TB dataset at 16K blocksize, no deduplication:

Primary database (/var/tmp/qdda.db) = 1TB/16K * (20 + 20) = 67 108 864 blocks * 40 ~ 2.6 GB.
staging database (/var/tmp/qdda-staging.db) = 2.6 GB (deleted after loading into the primary)
temp size for indexing/joining (/var/tmp/<hidden file>) = Roughly 50% of staging database ~ 1.3 GB

Reporting on large databases also requires some temp space. Note:

a) the larger the blocksize, the fewer rows are needed and the smaller the required space
b) the staging database contains a row for every scanned block
c) the primary database contains a row for every deduped block. If dedupe is 2:1 then the database size is 50%

These numbers can be calculated using the -t<size> option, for example for a 1TB dataset @ 16K: qdda -t1024
A 2TB dataset, 128K blocksize: qdda -B128 -T2048

If you need more space than available, you can change the locations of the files:

- Primary database with -f option (choose a filename for the database)
- Staging database and hidden directories with -T option (choose a temp directory)

Performance:

QDDA is mostly single threaded. The limit for reading data is defined by the CPU time it takes to calculate hashes and compression
sizes for each block, and insert speeds. Test scan speeds with the '-t 0' option. On my Intel i5-4440 I get a synthetic 
speed of about 500MB/s. During real scanning this drops to about 350 MB/s (due to the overhead of really reading data).

Merge performance - the database internally has to count, sort and join a lot of rows (each block is a row in the staging database).
Performance depends on CPU and I/O speed. Test the merging speed with the '-t size_gb' option. On my system the merge performance
is (for 16K blocksize on empty database, 2 threads):

Size (GB) Indexing(s)  Index(MB/s) Joining(s) Join(MB/s)
        2        0.08        27170       0.16      12931
       16        0.77        21251       1.35      12099
       64        3.71        17654       5.56      11781
      128       19.81        13230      23.57      11121
     1024       53.52        19592      98.39      10657

Tuning:

You may speed up I/O by altering the default database location from /var/tmp/qdda.db to another path with '-f',
on a faster file system (such as SSD based). 
You can also set the SQLite TEMP dir to an alternative location with -T (also if you run out of diskspace).

You can avoid the merge (join/sort) phase and delay it to a later moment using the "-r" (no report) option. 
Ideal if you scan on a slow server with limited space and you want to do the heavy lifting on a faster host later.

Merging datasets:

You may want to scan data and analyze dedupe ratios across different hosts. You can scan each host separately and then later combine
the databases by using the import option (add data of 2nd database to the primary). The block sizes of both databases should match.

Adding new streams/files to an existing database:

Use the "-a" (append) option to avoid overwriting (deleting) the existing database.

Dump: if you want to find out why certain blocks will or will not duplicate against each other, you can run the Dump (-d) option.
Beware that this slows down the scan process significantly because every block hash and compressed size will be listed to the console.
Ideally you should only use this for small size test scenarios.

Extended reports:

The -x (extended reports) option provides deep insight in deduplication and compression. 

The deduplication histogram shows detailed distribution of dedupe counts i.e. how many unique blocks are in the dataset, etc.
The Compression histogram shows the detailed compress bucket allocation for a given compression method.

Run as non-privileged user:

For added safety you may run qdda as a non-privileged user. Non-root users usually do not have access to block devices.

To run QDDA in a safe way, there are various methods (assuming the "qdda" user without root privileges):

- Add qdda to group "disk". Still unsafe as the "disk" group has read/write access to disks.
- Use "sudo cat /dev/<disk> | qdda <options>". Requires sudo access for qdda, still unsafe.
- Use named pipes: 
  as root run 'mkfifo /tmp/p ; cat /dev/<disk> > /tmp/p'
  as qdda run 'qdda <options> /tmp/p'
  This still requires some commands to be run as 'root' which opens the gates for mistakes.
- Change the group/permissions on /dev/<disk>: problematic as it either gives all users read access (chmod 664) or alters permissions
  for other applications such as Oracle ASM (chgrp qdda /dev/<disk>; chmod 640 </dev/disk>)

The best solution I have found is to use extended ACLs on Linux:

setfacl -m u:qdda:r /dev/<disk>

This gives qdda read-only access without altering any of the existing ownerships/permissions. The permissions will be reset at next reboot.
You need to have ACL enabled on the root file system (holding /dev/) and the setfacl tool installed (RPM package acl).

Run qdda over a network pipe:

You can do this using netcat (nc)

target host: (as qdda) nc -l 19000 | qdda
source host: (as root) cat /dev/<disk> | nc targethost 19000

Custom queries:

The database is standard SQLite and if you want to run your own queries, you can. Just type "sqlite /var/tmp/qdda.db" and you can run any SQLite
statement you like.

Troubleshooting:

If you don't get the dedupe results you expect, make sure you have the correct block alignment. Especially with (unnamed) pipes this can be tricky.
If blocks are shifted by just one byte, then all hashes will be different and analyzing two streams will result zero deduplication effect.


